# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U42iM6D13C4YUcmtaWn_huefZNXEhA2_
"""

from bs4 import BeautifulSoup as bs
import requests
# !pip install fake_headers
from fake_headers import Headers
import pandas as pd
import numpy as np

salaryes = []
min = []
max = []

hh_attrs_title = {'class':'bloko-link', 'data-qa':'vacancy-serp__vacancy-title'}

def hh_run(search, attrs_title):
    search = search.lower().replace(' ', '-')
    url = f'https://krasnoyarsk.hh.ru/search/vacancy?clusters=true&area=54&enable_snippets=true&salary=&st=searchVacancy&text={search}'
    headers = Headers(headers=True).generate()
    response = requests.get(url, headers=headers).text
    soup = bs(response, 'lxml')
    titles = [i.text for i in soup.findAll(attrs=attrs_title)]
    emploers = [i.text.replace("\xa0", ' ') for i in soup.findAll(attrs={'data-qa': 'vacancy-serp__vacancy-employer'})]
    urls = [i['href'] for i in soup.findAll(attrs={'class': "vacancy-serp-item", 'class': 'bloko-link', 'data-qa': 'vacancy-serp__vacancy-title'})]
    for i in urls:
        response_link = requests.get(i, headers=headers).text
        souplink = bs(response_link, 'lxml')
        salary = souplink.find(class_= 'vacancy-salary').text
        salary = salary.replace("\xa0", '')
        salaryes.append(salary)
        salary_list = salary.split(' ')
        if salary_list[1].isdigit():
            min.append(salary_list[1])
        else:
            min.append('зп не указано')
        if len(salary_list) > 3:
            if salary.split(' ')[3].isdigit():
                max.append(salary.split(' ')[3])
            else:
                max.append('не указано')
        else:
            max.append('зп не указано')

    
    dt = pd.DataFrame({'должность': titles,
                       'работадатель': emploers,
                       'ссылка': url,
                       'минимальная зп': min,
                       'максимальная зп': max,
                       'источник': 'hh.ru'})
    
    print(len(titles), len(emploers), len(urls), len(salaryes), len(min), len(max))
    return dt

def sj_run(search):
    search = search.lower()
    url = f'https://krasnoyarsk.superjob.ru/vacancy/search/?keywords={search}'
    headers = Headers(headers=True).generate()

    response = requests.get(url, headers=headers).text
    soup = bs(response,'lxml')
    
    titles = [i.text for i in soup.findAll(attrs={'class': 'f-test-search-result-item', 'class': '_1h3Zg _2rfUm _2hCDz _21a7u'})]
    urls = ['https://krasnoyarsk.superjob.ru' + i.a['href'] for i in soup.findAll(attrs={'class': 'f-test-search-result-item', 'class': '_1h3Zg _2rfUm _2hCDz _21a7u'})]
    emploers = [] # так как не всегда указан работатдель в результатах поиска, переходим на каждую страницу и берем от туда
    for i in urls:
      response = requests.get(i, headers=headers).text
      soup_em = bs(response,'lxml')
      emploer = soup_em.find(attrs={"class": '_2g1F-', 'class':'_1h3Zg _2rfUm _2hCDz _2ZsgW _21a7u _2SvHc'})
      if emploer is not None:
          emploers.append(emploer.text)
      else:
          emploer = soup_em.find(attrs={"class": '_2g1F-'})
          emploers.append(emploer.span.text)
    salary_list = [i.text.replace("\xa0", '').replace('руб./месяц', '').rstrip() for i in soup.findAll(attrs={'class': 'f-test-search-result-item', 'class': '_1OuF_ _1qw9T f-test-text-company-item-salary'})]
    min_sj = []
    max_sj = []
    for i in salary_list:
        if i.find('—') != -1:
            min_sj.append(i[0:i.find('—')])
            max_sj.append(i[i.find('—')+1:])
        if i[:2] == 'от':
            min_sj.append(i[2:])
            max_sj.append('не указано')
        if i.isdigit():
            min_sj.append(i)
            max_sj.append('не указано')
        if i == 'По договорённости':
            min_sj.append('По договорённости')
            max_sj.append('По договорённости')
        if i[:2] == 'до':
            max_sj.append(i[2:])
            min_sj.append('не указано')
    print(len(titles),len(emploers),len(urls),len(min_sj), len(max_sj), len(salary_list))
    
    dt = pd.DataFrame({'должность': titles,
                       'работадатель': emploers,
                       'ссылка': url,
                       'минимальная зп': min_sj,
                       'максимальная зп': max_sj,
                       'источник': 'superjob.ru'})
    return dt

name = 'Аналитик'
h = hh_run(name, hh_attrs_title)
s = sj_run(name)
rez = pd.concat([h, s], ignore_index=True) 
rez.to_csv('sum.csv')
